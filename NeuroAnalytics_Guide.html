<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>NeuroAnalytics Guide - Qneuro</title>

    <style>
        @import url("https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap");

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html,
        body {
            font-family: "Roboto", sans-serif;
            font-weight: 300;
            line-height: 1.4;
            scroll-behavior: smooth;
            height: 100%;
        }

        body {
    display: flex;
    flex-direction: column;
    height: 100vh;
    overflow: hidden;
}

        a {
            text-decoration: none;
            color: inherit;
        }

        /* ================= LEFT SIDEBAR ================= */

        header {
            width: 280px;
            height: 100vh;
            position: sticky;
            top: 0;
            border: 1px solid #ccc;
            background: #fff;

            overflow-y: auto;   /* ✅ LEFT SCROLL */
            overflow-x: hidden;
        }

        header img {
            display: block;
            margin: 20px auto;
        }

        nav h1 {
            font-size: 1.5rem;
            padding: 10px;
            border-bottom: 1px solid #ccc;
            text-align: center;
        }

        nav ul {
            list-style: none;
        }

        nav ul li {
            padding: 10px;
            border-bottom: 1px solid #ccc;
            color: darkblue;
        }

        nav ul li:hover {
            background: #ccc;
            transition: 0.3s ease-in-out;
        }

        nav ul ul li {
            padding-left: 25px;
            font-size: 14px;
        }

        /* ================= RIGHT CONTENT ================= */

        main {
            flex: 1;
            padding: 50px;
            background-color: lavender;

            height: 100vh;
            overflow-y: auto;   /* ✅ RIGHT SCROLL */
        }

        section {
            margin-bottom: 40px;
            scroll-margin-top: 50px;
        }

        section h2 {
            font-size: 24px;
            color: darkblue;
            border-bottom: 1px solid #ccc;
            margin-bottom: 20px;
        }

        section article {
            max-width: 1200px;
            font-size: 18px;
            display: flex;
            flex-direction: column;
            gap: 15px;
        }

        section article ul {
            margin-left: 30px;
        }

        section article ul li {
            margin-bottom: 10px;
        }

        code {
            display: block;
            background-color: #f7f7f7;
            padding: 15px;
            border-radius: 5px;
            white-space: pre-line;
            line-height: 1.8;
        }

        .step {
            margin-bottom: 20px;
        }

        .step b {
            display: block;
            margin-bottom: 5px;
        }

        .step img {
            display: block;
            margin-top: 10px;
            max-width: 100%;
        }

        section article h3 {
            font-size: 20px;
            margin-top: 20px;
            color: #333;
        }

        section article h3::before {
            content: "➤ ";
            color: darkblue;
        }

        /* ================= FOOTER ================= */

footer {
    height: 40px;
    background: #fff;
    border-top: 1px solid #ccc;
    text-align: center;
    font-size: 14px;
    color: #555;
    display: flex;
    align-items: center;
    justify-content: center;
}

/* PAGE WRAPPER */
.page {
    display: flex;
    flex: 1;
    gap: 10px;
    overflow: hidden;
}
    </style>
    
</head>

<body>

    <div class="page">
    
    <header>
    <img src="https://assets.tes.com/magazine-attachments/s3fs-public/media/image/live/1d372446-5056-b759-2a1b9b950a8d161f-logo.png"
         alt="Qneuro Logo"
         width="150" />

    <nav>
        <h1>NeuroAnalytics Guide</h1>
        <ul>
            <li><a href="#intro">Introduction</a></li>
            <li><a href="#software">Software Installation & License Activation</a></li>
            <li>
            <ul><a href="#ftp">Step to Open FTP Server & Downloading Application</a></ul>
            <li>
                <a href="#license">NeuroAnalytics License Flow</a>
                <ul>
                    <li><a href="#activation">1. License Activation</a></li>
                    <li><a href="#renewal">2. License Renewal</a></li>
                    <li><a href="#revocation">3. License Revocation</a></li>
                </ul>
            </li>
        </li>
            <li>
                <a href="#flow">NeuroAnalytics Flow</a>
                <ul>
                    <li><a href="#cap">1. Cap Connection</a></li>
                    <li><a href="#signal">2. Signal Quality Index</a></li>
                    <li><a href="#eeg">3. EEG and its App Features</a></li>
                    <li><a href="#ppg">4. PPG and its App Features</a></li>
                    <li><a href="#imu">5. IMU and its App Features</a></li>
                    <li><a href="#analysis">6. Analysis</a></li>
                    <li><a href="#path">7. File Save Path</a></li>
                    <li><a href="#previous">8. Previous Records</a></li>
                </ul>
            </li>

            <li>
                <a href="#lsl">LSL Streaming and Viewing</a>
                <ul>
                    <li><a href="#stream">1. Streaming LSL</a></li>
                    <li><a href="#view">2. Viewing LSL</a></li>
                    <li><a href="#dummy"> </a></li>
                </ul>
            </li>

        </ul>
    </nav>
</header>

<main>
    <section id="intro">
        <h2>Introduction</h2>
        <article>
            <p>H100 is an advanced wearable neurotechnology device developed by Qneuro that integrates multimodal physiological sensing into a single, comfortable hat form factor designed 
                specially for researchers and consumers. It is designed to support real-time brain monitoring, cognitive performance tracking, and mental state optimization for both research 
                and wellness applications.</p>

            <p>
                At its core, H100 combines:
                <ul style="list-style-type: disc;">
                    <li style="margin-bottom: 12px;"> <b>High-fidelity electroencephalogram (EEG)</b> — capturing electrical brain activity from multiple channels.</li>
                    <li style="margin-bottom: 12px;"> <b>Photoplethysmography (PPG) sensors</b> — monitoring cardiovascular signals like heart rate and blood volume changes.</li>
                    <li><b> Inertial measurement unit (IMU)</b> — sensing movement, posture, and acceleration.</li>
                </ul>
            </p>

            <p>
                The device communicates wirelessly (via Bluetooth) with a companion app on diverse operating platforms like Android, macOS, and iOS, enabling <b>live data 
                streaming, visualization, and recording</b> along with advanced analytics. 
                <br><br>
                Unlike typical consumer wearables, H100  is engineered with research-grade components:
                <ul style="list-style-type: disc;">
                    <li style="margin-bottom: 12px;">8-channel EEG with 24-bit data resolution and up to 250 Hz sampling rate, which cover frontal, central, and occipital brain regions.</li>
                    <li style="margin-bottom: 12px;">2-channel PPG sensors (i.e. red & infrared) for cardiovascular data with up to 100 Hz sampling rate.</li>
                    <li>A 9-axis IMU including accelerometer, gyroscope, and magnetometer for motion tracking with up to 100 Hz sampling rate .</li>
            </p>
        </article>
        <article>
        <h3 style="font-size: 24;">Key Features & Capabilities</h3>

                <h4 style="font-size: 18;">Multimodal Physiological Monitoring</h4>
                H100 simultaneously records electrical brain activity, heart physiology, and motion data, providing a comprehensive, time-aligned dataset for 
                deeper insight into brain-body interactions.

                <h4 style="font-size: 20;">Real-Time Data Streaming</h4>
                Wireless Bluetooth connectivity enables real-time streaming of all sensor modalities to mobile devices or PCs, making the platform ideal for 
                live monitoring, research experiments, or neurofeedback applications.

                <h4 style="font-size: 20;">Advanced Analytics & Training</h4>
                Paired with the NeuroAnaytics app (predominantly designed for Researchers and Academicians), users can access built-in analytics, brain training modules, 
                and personalized metrics to support wellbeing goals like enhanced focus, reduced stress, improved memory, and sleep optimization.

                <h4 style="font-size: 20;">User-Centered Design</h4>
                The ergonomic hat/headset form factor ensures comfort for prolonged use, and patented electrode technology allows reliable EEG acquisition even over hair.              

        <h3 style="font-size: 24;">Use Cases</h3>
        H100 fits a wide range of applications:
                <ul style="list-style-type: disc;">
                    <li style="margin-bottom: 12px;"><b>Academic & Clinical Research:</b> Cognitive neuroscience, brain-computer interfaces, multidisciplinary studies involving brain, 
                        heart, and motion data.</li>
        </article>
        <article>
        NeuroAnalytics is an application used to stream, view, record and save the data of EEG, PPG, IMU and other derivatives from the H100. We can see it in detail in upcoming sections.
        </article>
    </section>
    <section id="software">
        <h2>Software Installation & License Activation</h2>
    <section id="ftp"> 
        <h2>Step to Open FTP Server & Downloading Application</h2>
        <article>
            <div class="step">
                <b>Step 1:</b>
                Launch File Explorer on your device.
                <img src="https://github.com/kavinkumarqneuro123/NeuroAnalytics-Guide-Qneuro/blob/main/4.3.png?raw=true" alt="Step 1" />
            </div>

            <div class="step">
                <b>Step 2:</b>
                Enter the FTP URL in the address bar and press Enter.
                <img src="https://github.com/kavinkumarqneuro123/NeuroAnalytics-Guide-Qneuro/blob/main/4.1.png?raw=true" alt="Step 2" />
            </div>

            <div class="step">
                <b>Step 3:</b>
                Enter the username and password, then click <i>Log On</i>.
                <img src="https://github.com/kavinkumarqneuro123/NeuroAnalytics-Guide-Qneuro/blob/main/4.2.PNG?raw=true" alt="Step 3" width="500" />
            </div>

            <div class="step">
                <b>Step 4:</b>
                The server opens successfully after login.
                <img src="https://github.com/kavinkumarqneuro123/NeuroAnalytics-Guide-Qneuro/blob/main/4.4.png?raw=true" alt="Step 4" />
            </div>

            <div class="step">
                <b>Step 5:</b>
                Copy the file, paste it locally, extract it, and start using NeuroAnalytics.
            </div>

        </article>
    </section>

<section id="license">
    <h2>NeuroAnalytics License Flow</h2>
    <article>

        <p>
            After extracting the application, install it and activate the license.
            The license can be activated, renewed, or revoked as described below.
        </p>

        <!-- License Activation -->
        <h3 id="activation">1. License Activation</h3>
        <ul>
               <article>

            <div class="step">
                <b>Step 1: Open the Application</b>
                    When you launch the software for the first time, the <i>'Activate 
                    License'</i> screen will appear automatically.
                <img src="https://github.com/kavinkumarqneuro123/NeuroAnalytics-Guide-Qneuro/blob/main/1.png?raw=true" alt="Step 1" />
            </div>

            <div class="step">
                <b>Step 2: Enter Your License Key</b>
                You will see a field labeled <i>'License Key'</i>.
                
                <ol style="margin-left: 40px;"><br> <li>Type your license key in the provided field.</li>
                <li>Make sure the key is entered exactly as given to you (for example: A1B2-C3D4-E5F6-G7H7).</li></ol>
                <br>Once the key is entered correctly, click the <i>"LINK"</i> button.
                <img src="https://github.com/kavinkumarqneuro123/NeuroAnalytics-Guide-Qneuro/blob/main/2.png?raw=true" alt="Step 2" />
            </div>

            <div class="step">
                <b>Step 3: Wait for License Verification</b>
             <p>After clicking <i>LINK</i> the system will verify your license key. </p>
                <ul style="margin-left: 40px;"><br> <li>
                An active internet connection is required for this step.</li>
          <li> Please wait while the software securely checks and links your license.</li>
          </ul>
            </div>

            <div class="step">
                <b>Step 4: Confirmation</b>
                If the license key is valid and successfully linked, a confirmation window will appear:
                <br>
                <img src="https://github.com/kavinkumarqneuro123/NeuroAnalytics-Guide-Qneuro/blob/main/3.png?raw=true" alt="Step 4" />
            </div>
           <p>Click <b>OK</b> to Continue.</p>

                   <div class="step">
            <br><b>Step 5: Begin Using the Application</b>
                <ul style="margin-left: 40px;">
                    <li>After confirming, you will be taken to the main screen where you can enter your username and 
                    begin using the application.</li>
                    <li>Your license activation is now complete.</li>
                    </ul>
                <img src="https://github.com/kavinkumarqneuro123/NeuroAnalytics-Guide-Qneuro/blob/main/4.png?raw=true" alt="Step 5" />

            </div>
             </ul>

        <!-- License Renewal -->
        <h3 id="renewal">2. License Renewal</h3>
        <ul>
            <li>License renewal is required before the current license expires.</li>
            <li>Use the renewal key provided for monthly or annual subscriptions.</li>
            <li>Ensure an active internet connection during renewal.</li>
        </ul>

        <!-- License Revocation -->
        <h3 id="revocation">3. License Revocation</h3>
        <ul>
            <li>Revocation is required when moving the license to another system.</li>
            <li>Deactivate the license from the current system.</li>
            <li>Once revoked, the same license key can be reused on a new system.</li>
        </ul>

    </article>
</section>
<section id="flow">
    <h2>NeuroAnalytics Flow</h2>
    <article>
    <p>
        Let’s see the detailed software flow and functionalities of NeuroAnalytics application.
        <br><br>In the below sub-sections, you will get glimpses of launching the application till 
        saving the files in the destination folder.  
        <br><br><i>Note: The data present in the stream (EEG, PPG and IMU) is subjective to the user. It doesn’t 
            imply the intent to have the same quality or values.</i> 
    </p>
    </article>
    <article>
        <h3 id="cap">1. Cap Connection</h3>
        <h4 style="font-size: 20;">  Launch of Application</h4>
        <p>
            Launch the NeuroAnalytics <b>(QneuroNeuroAnalytics.exe)</b> Application after activating the license. 
            <br>
            <br>In default, <b>‘SINGLE USER’</b> is enabled. It denotes that the device (Hat) is getting streamed in the 
            particular system only via Bluetooth. 
            <br>
            <br>At the top-right corner, <b>‘USB’</b> option is also present. It is enabled when you connect the Hat with 
            the application via USB port. You can either use “Bluetooth” or use the “USB” option.
            <br><br>We’ll elaborate on <b>Streaming-LSL</b> and <b>Viewing-LSL</b> in upcoming sub-sections.
            <br><br>
            <i>Image>></i>
        </p>
        <h4 style="font-size: 20;"> Entering User Name</h4>
        <p>
            After clicking the <b>‘PROCEED’</b> button, the next screen opens where you need to enter the username of your choice to 
            create the folder in local C drive and files will be saved in the folder.
            <br><br><i>Image>></i>
            <br><br>
            You can see the option, <b>‘VIEW USER RECORDS’</b> where you can see the previous records done in the system using the application. 
            <br><br>
            Once you click the ‘VIEW USER RECORDS’ it shows the previous records “User Name” irrespective of dates. The <b>‘SELECT USER’</b> 
            can be empty if you are using the application as a 1st time user.
            <br><br>
            In below images, after clicking the specific user name (here  ‘test’ is used for reference’), it shows the available data as shown in the <b>‘SESSION RECORDINGS’</b>.
            <br><br><i>Image>></i>
            <br><br>
            After entering the <b>‘User Name’</b>, click ‘Proceed’ to connect the NeuroState device with the application. After clicking ‘Proceed’, 
            it shows <b>‘Searching for Bluetooth Connection’ as shown in the below image</b>.
            <br><br><i>Image>></i>
            <br><br>Once ‘Searching for Bluetooth Connection’ is done, it shows the name of the NeuroState device(s) connected with the system’s bluetooth (For eg., NeuroState-F266) 
            in <b>‘Available Devices’</b>.
            <br><br><i>Image>></i>
            <br><br>If many NeuroState devices are connected via bluetooth to your system, it shows all the device IDs in ‘Available Devices’ as shown below. Only click on the device 
            that you need to connect. 
            <br><br><i>Image>></i>
            <br><br>If the device is not turned ON, while clicking on the Device ID shows the below message as <b>‘Connection Failed’</b>. 
            <br><br><i>Image>></i>
        </p>
    </article>
    <article>
        <h3 id="signal">2. Signal Quality Index</h3>
        <p>
            After clicking on the device to connect with the NeuroAnalytics applications, it directs to the next page which is <b>“Signal Quality Index”</b>. In this page, you can verify the 
            signal quality of EEG and PPG and it just takes a few seconds of time to show the signal quality status.
            <br><br><i>Image>></i>
            <br><br>
            After 5 seconds, EEG signals tend to show its results whether the electrode placed picks the signals with Low/Medium/High Quality. Low Quality denotes that the signals have more 
            noise due to improper contact or external noise interference. Adjust the particular electrode to make the signal to clean EEG. If the signal quality is medium, it denotes that there is little noise interference over the actual EEG signals.
            <br><br>
            Also, PPG present in the earlobe area needs to be adjusted if it shows the quality as ‘Low’. Make sure that PPG forms the below typical pattern. 
            <br><br><i>Image>></i><br><br>
            After doing adjustments, stay calm for a few seconds to reflect the quality of EEG/PPG without further disturbing the electrodes by staying calm.
            <br><br>
            Once both of the signal quality is ‘High’ i.e., all the channel positions show Green, click ‘Proceed’.
            <br><br><i>Image>></i><br>
        </p> 
    </article>
    <article>
         <h3 id="eeg">3. EEG and its App Features</h3>
         <p>
            Now, it directs to the page, where the actual data stream begins. 
            <br><br>The layout has the different panels as EEG, PPG, IMU and Analysis. 
            <br><br>Each panel has sub-panels. 
         </p>      
            <h4 style="font-size: 20;"> EEG:</h4>
        <p>
            EEG is streamed as 8 channels (FP1, FP2, O1, O2, C3, Cz, F, and C4). 
            <br><br>FP1 and FP2 channels touch the frontal (forehead skin) part and pick the respective signals. 
            <br><br>O1 and O2 channels pick signals from the occipital lobe.  
            <br><br>C3 and C4 channels pick signals from the frontal central part. 
            <br><br>Reference is present in one side of the earlobe and the other side has the PPG sensor.
            <br><br><i>Image>></i>
            <br><br>There are dropdowns to select and perform the certain features. 
            <br><br>In default, <b>‘Filter1’</b> Section  is used to apply a Bandpass filter of the interest that you need for 
            visual analysis. 
            <br><br><i>Image>></i>
            <b>‘Marker’</b> section is used to provide internal markers. In brief, markers are the representation of ascertain events 
            in which the data is actually used for analysis. Markers can be a numerical or alphabetical text. 
            <br><br><i>Image>></i>
            <br><br>In the ‘Marker’ Text box, you can enter the desired marker(s). By pressing ‘Start’, the particular event starts 
            and by pressing ‘Stop’, the particular event ends. 
            <br><br><i>Image>></i>
         </p> 
         <h4 style="font-size: 20;"> ASR Data Recording:</h4>
         <p>
            ASR - Artifact Subspace Reconstruction is used to remove the artifacts created by eye blinks, muscle and eyeball movements. 
            <br><br><i>Image>></i>
            <br><br>To perform ASR, baseline needs to be recorded first. Baseline is a combination of data recording during eyes open and eyes close 
            for specified time with no/very less movements. 
            <br><br><i>Image>></i>
            <br><br>Once baseline gets over, it shows ‘Session Ended’. Click on ‘Proceed’ to visualize the ASR data stream.
            <br><br>Click the <b>‘ASR’</b> to begin with the ASR recording.
            <br><br><i>Image>></i>
            <br><br>ASR is generally turned off. When you turn on the ASR, it asks for the baseline to record a fresh <b>(Record)</b> or Use the previous 
            recorded baseline <b>(Use previous)</b>. 
            <br><br>You can prefer a previously recorded baseline only when you didn’t remove the hat from your head. In any case, if you remove the hat, 
            you need to do a fresh baseline for the ASR data stream. 
            <br><br><i>Image>></i>
            <br><br>Once you turn off the ASR, you can visualize the blinks and some external artifacts present within the frequency range. Whereas in the 
            case when ASR is turned on, you can see the signals are free from artifacts such as blinks and movements. 
         </p>
         <h4 style="font-size: 20;"> Vertical Scale:</h4>
         <p>
            Vertical scale <b>(Vert-Scale)</b> is used to scale up/down the amplitude of EEG signals. By default, the scale is 100. If you choose the scale less than 
            100, the amplitude looks larger and if you choose the scale higher than 100, the amplitude looks smaller. 
            <br><br><i>Image>></i>
         </p>
         <h4 style="font-size: 20;"> EEG LOOK BACK:</h4>
         <p>
            In the EEG <b>‘LOOK BACK’</b> section, you can visualize the signals from the start of the stream till instance.  You can drag the section present below the 
            Lookback to see the signals streamed 5 seconds/30 seconds/1 minute back and from the start of the EEG stream.
            <br><br><i>Image>></i>
            <br><br>Using Left/Right Shift, you can drag the EEG in the Lookback as per the seconds you choose to view. 
            <br><br><i>Image>></i>
            <br><br>In the <b>‘Markers’</b> section, you can see the markers whatever have been entered. Internally, there are some sections, which throw markers once it gets 
            started and finished. It will also be listed in the ‘Markers’ section. Once you click on the specific marker, it directs to the view when the markers get entered. 
            <br><br><i>Image>></i>    
         </p>
         <h4 style="font-size: 20;"> Theme Colour:</h4>
         <p>
            Our application can be experienced in 2 themes - <b>Blue</b> (Default) and <b>Black</b>. The user can choose any of the colors they prefer. 
            <br><br><i>Image>></i>
         </p>
         <h4 style="font-size: 20;"> FFT:</h4>
         <p>
            By clicking the <b>‘FFT’</b> you can see the FFT plot which plots amplitude over frequency.
            <br><br>EEG as a time domain signal is hard to explain which brain wave is dominant and it is hard to compare focus, relaxation, stress etc., FFT converts 
            time-domain EEG into frequency-domain which helps to know what the brain is doing i.e., easy to understand and meaningful.
            <br><br><i>Image>></i>
         </p>
         <h4 style="font-size: 20;"> BAND:</h4>
        <p>
            Next by clicking on ‘BAND’, you can visualize the band power which tells how strong a specific brain wave is in an EEG signal. The band power can be 
            calculated by taking the square of the FFT and then separate the bands ie. delta, theta, alpha, beta and gamma.
            <br><br>
            With the help of Band power, 
                <br>✔ Quantifies brain states                  
                <br>✔ Used in focus / engagement indices 
                <br>✔ Compares rest vs task 
                <br>✔ Tracks mental workload & stress.
            <br><br><i>Image>></i>
        </p>
        <h4 style="font-size: 20;"> Video Recorder:</h4>
        <p>
            There will be a <b>‘RECORDER’</b> option to record the application/computer screen and the subject’s movements using the front camera of PC/laptop 
            (if it is available). 
            <br><br><i>Image>></i>
            <br><br>In the below image, as no camera is available in PC, the below right panel shows the icon with “NOT RECORDING”. 
            <br><br><i>Image>></i>
            <br><br>Two videos will be saved as one is the entire application with camera recording and another is the camera recording.
            <br><br>There will be two options - <b>Recorder 1</b> and <b>Recorder 2</b>. Recorder 1 denotes the inbuilt camera source and Recorder 2 denotes the external camera 
            sources like OBS studio, Logitech Capture etc.,
            <br><br><i>Image>></i>
            <br><br>By clicking, ‘START RECORD’, the video recorder starts to record. In some cases, recording of video results in low FPS (Frames per second) which is negligible. 
            <br><br><i>Image>></i>
        </p>
        <h4 style="font-size: 20;"> Analysis Graph:</h4>
        <p>
            In the Analysis graph, you can acquire <b>CLI</b> (Cognitive Load Index), <b>CLI AVG</b> (Cognitive Load Index Average), <b>ATI</b> (Attention Index), <b>ATI AVG</b> 
            (Attention Index Average), <b>ALP</b> (Alpha Index), and <b>ALP AVG</b> (Alpha Index Average).
            <br><br><i>Image>></i>
        </p>
    </article>
    <article>
        <h3 id="ppg">4. PPG and its App Features</h3>
        <p>
            PPG is used to measure blood volume changes in the microvascular tissue. Here it works by emitting the light - Infrared and Red into the skin and detecting 
            the amount of light either absorbed or reflected by blood vessels.
            <br><br><i>Image>></i>
            <br><br>In default, the frequency range is set between 0.5 and 5 with a 4th order bandpass filter. By clicking the ‘ContentSize’ you can choose the time frame 
            either 5 secs (5) or 10 secs (10).
            <br><br><i>Image>></i>
            <br><br>If you click, ‘PPGOUTPUT’ tab, you can visualize the PPG along with its features like, Heart Rate, Respiratory Rate, SpO2, and other distinct features 
            like, HRV - Time Domain and Non-Linear features. 
            <br><br><i>Image>></i>
            <br><br>Exclusively, Heart Rate, Respiratory Rate and SpO2 is shown as bars by considering its main vitality. When it reaches the optimal range it turns Green 
            and when it reaches below threshold value, it turns Blue/Orange and when it reaches to low values, it turns to Red. 
            <br><br><i>Image>></i>
        </p>
    </article>
    <article>
        <h3 id="imu">5. IMU and its App Features</h3>
        <p>
            When you click on the IMU section, you will get two sub-sections: <b>IMU</b> and <b>IMUAXIS</b>. 
            <br><br>By clicking on IMU, you can see 7 channels of data - <b>AccX, AccY, AccZ, QuatX, QuatY, QuatZ, QuatW</b>. 
            <br><br>Here, AccX, AccY, AccZ denote accelerometer data. A quaternion is just a compact way to represent the orientation (rotation) of a signal or 
            sensor in 3D, without errors or jumps.
            <br><br>In signal processing, you often deal with: 
            <ol style="margin-left: 40px;">
                 <li>Amplitude</li>
                <li>Phase</li> 
                <li>Frequency</li> 
            </ol>
                A quaternion is similar to phase, but for 3D motion signals instead of 1D waves.
            <ul style="list-style-type: disc;">
                <li style="margin-bottom: 12px;"> When signals come from 3-axis sensors (like IMU: accelerometer, gyroscope, magnetometer)</li>
                <li style="margin-bottom: 12px;"> Each axis gives a signal (X, Y, Z) </li>
                <li style="margin-bottom: 12px;"> Orientation changes continuously over time Using angles (roll, pitch, yaw) causes instability (gimbal lock).</li>
</ul>
<p>
            Quaternions combine all 3 axes into one smooth, stable signal representation.
            <br><br><i>Image>></i>
            <br><br>By clicking <b>‘IMUAXIS’</b>, you can see the3-dimensional representation displaying the orientation of cap movements. 
            <br><br><i>Image>></i>
</p>
        </p>
    </article>

<article>
    <h3 id="analysis">6. Analysis</h3>
    <p>
        In the analysis section, you get to view all the 3 distinct signals - EEG, PPG and IMU in one screen entirely. 
        <br><br>
        Also, you can choose any of the features to view in the place of EEG, PPG and IMU.
        <br><br><i>Image>></i><br><br>
        The <b>‘ANALYSIS’</b> section is not meant for viewing just EEG, PPG and IMU. From the dropdown (present in all 3 sections) you can select the preferred analysis representation 
        (bar/graphs) that needs to be viewed. For example, from the dropdown which shows currently EEG can be modified of which needs to be viewed such as <b>‘PPG’</b>, <b></b>‘IMU’</b>, <b>‘LOOKBACK’</b>, 
        <b></b>‘BAND’</b>, <b>‘PPGOUTPUT’</b>, <b>‘IMUAXIS’</b>, <b>‘VIDEOREORDER’</b>, <b>‘FFT’</b>, <b>‘DECODER’</b>, <b>‘BAND’</b> and <b>‘PPGOUTPUT’</b>. 
        <br><br>
        The analysis chosen in any of the 3 windows cannot be chosen again in any of the windows. In default it selects the previous analysis representation. For example, if the EEG present 
        in the  Left side is selected to view in PPG present in the right side analysis window, the right side window shows EEG and the PPG gets viewed in the left side. 
        <br><br><i>Image>></i><br><br>
        After you click on the ‘Save’ button, it will take a few seconds to save all the data entities as the application will be run for a longer time duration. 
        <br><br>Once the files get saved, it shows the pop-up message, <b><i>File generated successfully’</b></i>. 
        <br><br><i>Image>></i><br><br>
        In the <b>‘Single-User’</b>, Right side of the application shows the below options which get enabled after stopping the stream except Signal Viewer Graph. 
        <br><br><i>Image>></i><br><br>
    </p>
        <h4 style="font-size: 20;"> Signal Viewer Graph</h4>
        <p>
            Signal Viewer Graph is non other than the streaming of signals and its derivatives. It is always enabled as it denotes that the signal is streaming from the device. 
            <br><br><i>Image>></i><br><br>
        </p>
        <h4 style="font-size: 20;"> Session Record</h4>
        <p>
            Session Recordings is used to upload the specific data to the desired server if you have any. There will be enormous data under the timestamps. You can choose which file(s) 
            need to be uploaded. After clicking ‘Upload’ it gets uploaded and shows ‘Delete’when you need to delete the uploaded data.
            <br><br><i>Image>></i>
        </p>
        <h3 id="path">File Save Path</h3>
        <p>
            Using the shortcut, ‘Windows + R', open ‘Run’ present in the system to run the command. 
            <br><br>Enter <b>‘appdata’</b> in the ‘Open:’ to open the appdata. 
            <br><br><i>Image>></i><br><br>
            All the NeuroAnalytics files will get saved in,<br>
            <span style="color: red;"><i>“C:\Users\{User_profile_name}\AppData\LocalLow\Qneuro\QneuroNeuroAnalytics\{UserName entered in the application}” </i></span><br>
(where, ‘User_profile_name’ differs for each system as the username is generated by the system)
        </p>
        <h3 id="previous">Previous Records</h3>
        <p>
            To access the previously recorded data and videos corresponding to the data record, there are 2 options, one is <b>'Past Session'</b> and the other is <b>'Past Video Session'</b>.
        </p>
            <h4 style="font-size: 20;"> Past Session</h4>
            <p>
                In the ‘Past Session’ you can access previous recordings by clicking the Dates. While clicking the date, you can see the list of all recordings made on that particular date. 
                You can go back to the previous screen by clicking ‘Back’.
                <br><br><i>Image>></i><br><br>
            </p>
            <h4 style="font-size: 20;"> Past Video Session</h4>
            <p>
                In the ‘Past Video Session’ you can access previous video recordings by clicking the Dates. You can go back to the previous screen by clicking ‘Back’.
                <br><br><i>Image>></i>
            </p>
</article>    
</section>
<section id="lsl">
    <h2>LSL Streaming and Viewing</h2>
    <article>
    <p>
        Lab streaming layer (LSL) is a single unit centralized collection of data displayed in time series. It is used for research purposes which has the aspects of time sync, networking etc., 
        It has the real-time access which is used to view and record the data.
        <br><br>LSL is used for general purpose and cross platform support. For example, the streaming LSL can be designed using UNITY and the viewing LSL can be designed using Python/MATLAB by 
        implementing the exact libraries of the “streaming” layer into the “viewer” layer platform.
        <br><br>Below are the two videos which show how streaming and viewing works in the NeuroAnalytics. Double click on Video 1 and Video 2 to open the video for playing. 
        <br><br><b><i>Video 1</i></b> shows how the streaming and viewing of EEG looks in two different systems. Here, the streaming of EEG is from the device present in the ‘Left’ and the streaming EEG signal 
        is viewed in the system present in the ‘Right’.
        <br><br><b><i>Video 2</i></b> shows the streaming and viewing of PPG signals in two different systems. Here, the streaming of EEG is from the device present in the ‘Left’ and the streaming EEG signal is 
        viewed in the system present in the ‘Right’.
        <br><br><i>Video1>></i>
        <br><br><i>Video2>></i>
    </p>
    <h3 id="stream">Streaming LSL</h3>
    <p>
        By selecting ‘STREAMING-LSL’, it streams the EEG, PPG, IMU data and its derivatives in the same application as well as it can be viewed in NeuroAnalytics or another application developed using Python, 
        MATLAB by calling the function (stream names).
        <br><br><i>Image>></i><br><br>
        To capture the external event(s) , if any, in the ‘Enter stream name..’ box, enter the name of the external event that has been defined and click ‘OK’. 
        <br><br><i>Image>></i><br><br>
        The external event used in this case is ‘protocol’. After entering the stream name, click <b>‘Proceed’.</b>
        <br><br><i>Image>></i><br><br>
        After proceeding to the recording by pressing ‘Proceed’, it follows the same steps as present in <a href="#cap"><span style="color: rgb(69, 140, 182);">Cap Connection</span></a> and 
        <a href="#signal"><span style="color: rgb(69, 140, 182);">Signal Quality Index</span></a>. 
        <br><br><i>Image>></i>
        <br><br><i>Image>></i><br><br>
    </p>
        <h4 style="font-size: 20;">Marker Stream Status</h4>
        <p>
            Marker Stream Status displays the external streams available which have been added before starting the stream. As the stream name ‘protocol’ is added before starting the stream, it is displayed 
            in <b>‘Green’</b> colour. Once the stream 'protocol' event or any available stream is closed, it shows the stream name in <b>‘Red’</b> colour. Click the ‘Refresh’ button for scanning the available streams.
            <br><br><i>Image>></i>
        </p>
    <h3 id="view">Viewing LSL</h3>
        <p>
            By selecting ‘VIEWING-LSL’, it captures the stream available which matches with the called function or stream name. Viewing LSL can be any of the applications which can detect the available streams 
            nearby which can be connected with the same internet or with different networks based on how the user computed the code in their application. 
            <br><br>Open NeuroAnalytics and select ‘VIEWING-LSL’ for viewing the streams from the available sources. 
            <br><br><i>Image>></i><br><br>
            If any external streams other than the EEG, PPG, IMU or Event available, enter the stream name in correct format. Please note that, stream name is case-sensitive. 
            <br><br><i>Image>></i>
            <br><br><i>Image>></i><br><br>
            It shows the available users for streaming the data. As ‘test’ is the stream name given in the ‘Stream-LSL’, the stream name is detected as both the systems have been connected with the same network. 
            Click on the <b>‘test’</b> to access the streams.
            <br><br><i>Image>></i>
            <br><br>Once it is clicked, it shows the stream status as shown below. Click ‘Proceed’ to stream the data of ‘test’.
            <br><br><i>Image>></i>
            <br><br>Now, it displays the EEG, PPG and IMU data. You can also save the data in the ‘Viewer-LSL’ by clicking the check box, ‘Save Data’. The data that gets saved will be the data after clicking 
            the <b>‘Save Data’</b>. Wait for some time for proper save of the data.
            </p>
            <h4 style="font-size: 20;">Select LSL Sender</h4>
            <p>
                By clicking on ‘Select LSL Sender’ you can see the available User streams connected with the same network. Click on ‘Refresh’ to capture any other streams at the moment. 
                <br><br><i>Image>></i>
                <br><br>When you click on the name of the available user, it shows the <b>‘Stream Status’</b>. Here, when I click on <b>‘test’</b> it shows the Stream Status and when you click Back, it shows the Users screen 
                and when you click on <b>‘Proceed’</b> it shows the stream page.
                <br><br><i>Image>></i>
            </p>
    </article>
</section>
</main>
</div>
<footer>
    © 2026 Qneuro India Pvt. Ltd. All rights reserved.
</footer>
</body>
</html>